---
title: "Intro to DS - HW09 KNN"
author: "Izzy Illari"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    css: styles.css
    code_folding: hide
    # number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F, message = F)
options(scientific=T, digits = 3) 
```

```{r basic, include=F}
# use this function to conveniently load libraries and work smoothly with knitting
# can add quietly=T option to the require() function
loadPkg = function(pkg, character.only = FALSE) { 
  if (!character.only) { pkg <- as.character(substitute(pkg)) }
  pkg <- ifelse(!character.only, as.character(substitute(pkg)) , pkg)  
  if (!require(pkg,character.only=T, quietly =T)) {  install.packages(substitute(pkg),dep=T); if(!require(pkg,character.only=T)) stop("Package not found") } 
}
loadPkg(knitr)

# unload/detact package when done using it
unloadPkg = function(pkg, character.only = FALSE) { 
  if(!character.only) { pkg <- as.character(substitute(pkg)) } 
  search_item <- paste("package", pkg,sep = ":") 
  while(search_item %in% search()) { detach(search_item, unload = TRUE, character.only = TRUE) } 
}
```


# Pima Dataset  

## Preparation and EDA  

### Question 1  
**Obtain the dataset**  
<div class="quote-container">

> In the `MASS` library, combine the two datasets `Pima.te` and `Pima.tr` back into one complete dataset, call it `pima`. (Try function `rbind()`.) How many observations are there? 

</div>

```{r import_data}
loadPkg(MASS)
data1 = MASS::Pima.te
data2 = MASS::Pima.tr
pima = rbind(data1, data2)
str(pima)
```

There are `r nrow(pima)` observations of `r ncol(pima)` variables in `pima`.

The dataset includes measurement on a population of women of Pima Indian heritage living near Phoenix, Arizona.

The women were tested for diabetes according to World Health Organization criteria.
The variables in the dataset are:  
* npreg : number of pregnancies.  
* glu : plasma glucose concentration  
* bp : diastolic blood pressure (mm Hg) skin triceps skinfold thickness (mm)  
* bmi : body mass index  
* ped : diabetes pedigree function  
* age : age in years  
* type : Yes or No: diabetic by WHO criteria  

### Question 2  
**Summary**  
<div class="quote-container">

> Obtain some basic summary data for pima. (You can try the `xkablesummary()` function introduced in the previous HW7 solution.) 

</div>
 

```{r xkablesummary, include=F}
loadPkg(xtable)
loadPkg(kableExtra)
loadPkg(stringi)

xkabledply = function(smmry, title='Caption', pos='left') { # Thanks Ryan Longmuir for the codes
  smmry %>%
    xtable() %>% 
    kable(caption = title, digits = 4) %>%
    kable_styling(position = "center") %>%
    kable_styling(bootstrap_options = "striped", full_width = F,
    position = pos)
}

xkablesummary = function(df) { 
  #' Combining base::summary, xtable, and kableExtra, to easily display numeric variable summary of dataframes. 
  #` If the categorical variables has less than 6 levels, the function will still run without error.
  #' ELo 202003 GWU DATS
  #' version 1
  #' @param df The dataframe.
  #' @return The summary table for display, or for knitr to process into other formats 
  #' @examples
  #' xkablesummary( faraway::ozone )
  #' xkablesummary( ISLR::Hitters )
  
  s = summary(df) %>%
    apply( 2, function(x) stringr::str_remove_all(x,c("Min.\\s*:\\s*","1st Qu.\\s*:\\s*","Median\\s*:\\s*","Mean\\s*:\\s*","3rd Qu.\\s*:\\s*","Max.\\s*:\\s*")) ) %>% # replace all leading words
    apply( 2, function(x) stringr::str_trim(x, "right")) # trim trailing spaces left
  
  colnames(s) <- stringr::str_trim(colnames(s))
  
  if ( dim(s)[1] ==6 ) { rownames(s) <- c('Min','Q1','Median','Mean','Q3','Max') 
  } else if ( dim(s)[1] ==7 ) { rownames(s) <- c('Min','Q1','Median','Mean','Q3','Max','NA') }
  
  s %>%
    xkabledply("Table: Statistics summary.", "center")

}

xkablevif = function(model) { 
  #' Combining faraway::vif, xtable, and kableExtra, to easily display numeric summary of VIFs for a model. 
  #' ELo 202003 GWU DATS
  #' version 1
  #' @param df The dataframe.
  #' @return The summary table for display, or for knitr to process into other formats 
  #' @examples
  #' xkablevif( model )
  
  vifs = table( names(model$coefficients)[2:length(model$coefficients)] ) # remove intercept to set column names
  vifs[] = faraway::vif(model) # set the values

  vifs %>%
    xtable() %>% 
    kable(caption = "VIFs of the model", digits = 4, col.names = 'VIF') %>% # otherwise it will only has the generic name as 'V1' for the first vector in the table
    kable_styling(position = "center") %>%
    kable_styling(bootstrap_options = "striped", full_width = F,
    position = "left")
}
```

Here is a table summarizing the staistics for each of the `r ncol(pima)` variables in `pima`:   

```{r summary_data}
xkablesummary(pima)
```


### Question 3  
**Pairs**  
<div class="quote-container">

> Another quick EDA to perform, you can plot the `pairs()`. The plot function can handle both numerical and categorical variable type. After trying the function in the R base library, also try the modified version with `pairs.panels()`.

</div>

```{r q3}
loadPkg(psych)
pairs.panels(pima, #data frame 
             method = "pearson", # correlation method
             hist.col = "#00AFBB", # set histogram color, can use "#22AFBB", "red",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
             )
unloadPkg(psych)
```

It seems that the data is not really highly correlated with each other. If we see straight lines in the scatter plots that shows a trend of zero correlation. The most correleted variables are `npreg` and `age`, with a correlation of `r cor(pima$npreg, pima$age)`, and `skin` and `bmi`, with a correlation of `r cor(pima$skin, pima$bmi)` 


## KNN  

### Question 4  
**Train-Test split 3:1**  
<div class="quote-container">

> In order to perform KNN analysis, we need to separate the X-variables and the y-labels. (Which should be our y-variable?) Before we separate them out, create a vector/array of 1 and 2 to create a train-test split in the ratio of 3:1. (Set a constant seed value so that we can duplicate the results.) So eventually, you will get the training Xs as a dataframe, training y-label (a vector), as well as the test sets together in four groups. Make sure the train-X and train-y are not mixed up in the ordering during the process. Same for test-X and test-y. 

</div>

First we want to scale the data so KNN will operate correctly and we use all columns except the last one bc the others are numeric and last is factor. Then we will set the seed, and create the test and train data sets. These will be made using a sample fraction. We want to create 2 data sets, and by using replacement this means we can reset the random sampling across each vector and the probability gives sample the weight of the splits, 3/4 for train, 1/4 for test. We want a ratio of 3:1, which means "three times" the original, or that the odds are less than 1 in 4 (4=1+3) or less than 25%. This means our train will be 75% and our test will be 25%. 

```{r q4a}
loadPkg(FNN)
end <- as.integer(ncol(pima)-1)
scaledpima <- as.data.frame(scale(pima[1:end], center = TRUE, scale = TRUE))
#set seed
set.seed(1000)
#sample 
pima_sample <- sample(2, nrow(scaledpima), replace=TRUE, prob=c(0.75, 0.25))
# train and test
pima_training <- scaledpima[pima_sample==1, 1:end]
pima_test <- scaledpima[pima_sample==2, 1:end]
```

Now that we have our train and test data we need to create our 'Y' variables or labels need to input into the KNN function. We shall use the last column, which is the only column with factor level variables. 

```{r q4b}
pima.trainLabels <- pima[pima_sample==1, ncol(pima)]
pima.testLabels <- pima[pima_sample==2, ncol(pima)]
```

And now with that done we can deploy our model. We shall use `k=3` initially, for the number of clusters.

```{r q4c}
pima_pred <- knn(train = pima_training, test = pima_test, cl=pima.trainLabels, k=3)
head(pima_pred)
loadPkg(gmodels)
IRISPREDCross <- CrossTable(pima.testLabels, pima_pred, prop.chisq = FALSE)
```


### Question 5  
**KNN results**  
<div class="quote-container">

> Perform the KNN analysis, with different k values. You do not need to show all the results from different k, but please include the one with the best (total) accuracy in your submission. How does the accuracy compared to the percentages of being T/F in the dataset? 

</div>

I'm going to split the data again, this time using `caret`.

```{r q5a}
loadPkg(ISLR)
loadPkg(caret)
indxTrain <- createDataPartition(y = pima$npreg, p = 0.75, list = FALSE)
training <- pima[indxTrain,]
testing <- pima[-indxTrain,]
```

Now I'm going to run KNN again using the 7 numeric variables as predictors and setting my model as `type ~ .`, which means that I'm checking to see if there are any clusters for the factor level variable `type` using all the other variables. 

```{r q5b}
#set.seed(400)
ctrl <- trainControl(method="repeatedcv", repeats = 3)
knnFit <- train(type ~ ., data = training, method = "knn", trControl = ctrl, 
                preProcess = c("center","scale"), tuneLength = 20)
knnFit
```

That's a long list, and it will be easier to look at it as a plot. I'm going to use plots to see optimal number of clusters, and plotting yields Number of Neighbours Vs accuracy (based on repeated cross validation)

```{r q5c}
plot(knnFit)
```


```{r q5d}
df_knn <- knnFit[[4]]
max_Acc <- max(df_knn$Accuracy)
index <- which(df_knn$Accuracy == max_Acc)
k_Acc <- df_knn[index,]$k
unloadPkg(ISLR)
unloadPkg(caret)
```

According the the above we have that the max accuracy is `r max_Acc`, which happens when k = `r k_Acc`. I will use this `k` value and reproduce my earlier work.

```{r q5e}
pima_pred <- knn(train = pima_training, test = pima_test, cl=pima.trainLabels, k=k_Acc)
head(pima_pred)
IRISPREDCross <- CrossTable(pima.testLabels, pima_pred, prop.chisq = FALSE)
```

**can we use the elbow method to check**







## Logistic Regression and comparison  

### Question 6   
**Logistic Regression results**  
Compare to the best logistic regression you can get. (Use the full model with all variables, since that is what we have for KNN.) How is the accuracy (assumes the standard cutoff of 0.5) compared to KNN? 

I am going to make a logistic model using all the variables.

```{r q6a}
pima_logit <- glm(type ~ ., data = pima, binomial(link = "logit"))
summary(pima_logit)
exp(coef(pima_logit))
```

Not all of the coefficients are statistically significant at the $\alpha$ level of 0.05 in this model, as we can see from the summary above. 

```{r q6b}
coeff_logit <- summary(pima_logit)$coefficients
logit_df <- as.data.frame(coeff_logit)
stat_sig_logit1 <- logit_df[ which(logit_df$"Pr(>|z|)" < 0.001), ]
stat_sig_logit2 <- logit_df[ which(logit_df$"Pr(>|z|)" < 0.01
& logit_df$"Pr(>|z|)" > 0.001), ]
```

The most significant (***) variables are the following,

```{r q6c}
format(stat_sig_logit1, digits = 5) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

and then the second most significant (**) variables are the following,

```{r q6d}
format(stat_sig_logit2, digits = 5) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

Now we can look at the accuracy and the confusion matrix of our logit model. 

```{r confusionMatrix8}
loadPkg(regclass)
pima_logit_confusion = confusion_matrix(pima_logit)
unloadPkg(regclass)
```

```{r, results="asis"}
xkabledply(pima_logit_confusion,"Confusion Matrix: Logit model 2, cutoff = 0.5")
```

We can use the Hosmer and Lemeshow Goodness of Fit test to evaluate logistic regression fit. 

```{r HosmerLemeshow8}
loadPkg(ResourceSelection) # function hoslem.test( ) for logit model evaluation
pima_logit_Hoslem <- hoslem.test(pima$type, fitted(pima_logit)) # Hosmer and Lemeshow test, a chi-squared test
unloadPkg(ResourceSelection) 
pima_logit_Hoslem
```

The Hosmer-Lemeshow statistic indicates a poor fit if the significance value is less than 0.05. The p-value of `r format(pima_logit_Hoslem$p.value, digits = 5)` is below 0.05 which indicates the model is not really a good fit, despite the fact that several of the coefficients are significant. 

Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC) measures the true positive rate (or sensitivity) against the false positive rate (or specificity). The area-under-curve is always between 0.5 and 1. Values higher than 0.8 is considered good model fit. 

```{r roc_auc8}
loadPkg(pROC) # receiver operating characteristic curve, gives the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve is on sensitivity/recall/true-positive-rate vs false_alarm/false-positive-rate/fall-out.
pima_prob <- predict(pima_logit, type = c("response"))
pima$prob <- pima_prob
h_pima <- roc(type~prob, data=pima)
auc(h_pima) # area-under-curve prefer 0.8 or higher.
plot(h_pima)
```

We have here the area-under-curve of `r auc(h_pima)`, which is better than 0.8, and is considered a good model.

McFadden is another evaluation tool we can use on logit regressions. This is part of what is called pseudo-R-squared values for evaluation tests. We can calculate McFadden statistics for our model.

```{r McFadden8}
loadPkg(pscl) # use pR2( ) function to calculate McFadden statistics for model eval
pima_logit_2pr2 <- pR2(pima_logit)
pima_logit_2pr2
unloadPkg(pscl) 
```

With the McFadden value of `r round(pima_logit_2pr2['McFadden'], digits=3)`, which is analgous to the coefficient of determination $R^2$, only about `r 100*round(pima_logit_2pr2['McFadden'], digits=2)`% of the variations in y is explained by the explanatory variables in the model. 



```{r, include=FALSE}
unloadPkg(pROC)
unloadPkg(MASS)
unloadPkg(xtable)
unloadPkg(kableExtra)
unloadPkg(stringi)
unloadPkg(FNN)
unloadPkg(gmodels)
unloadPkg(ggplot2)
```



