---
title: "Intro to DS - HW07 Feature Selection"
author: "Izzy Illari"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float: yes
    keep_tex: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F, results = T, message = F, scientific=T)
options(scientific=T, digits = 3) 
```

```{r basic, include=F}
loadPkg = function(pkg, character.only = FALSE) { 
  if (!character.only) { pkg <- as.character(substitute(pkg)) }
  pkg <- ifelse(!character.only, as.character(substitute(pkg)) , pkg)  
  if (!require(pkg,character.only=T, quietly =T)) {  install.packages(substitute(pkg),dep=T); if(!require(pkg,character.only=T)) stop("Package not found") } 
}
loadPkg(knitr)

# unload/detact package when done using it
unloadPkg = function(pkg, character.only = FALSE) { 
  if(!character.only) { pkg <- as.character(substitute(pkg)) } 
  search_item <- paste("package", pkg,sep = ":") 
  while(search_item %in% search()) { detach(search_item, unload = TRUE, character.only = TRUE) } 
}
```

```{r outlierKD, echo=F}
# By Klodian Dhana, https://www.r-bloggers.com/identify-describe-plot-and-remove-the-outliers-from-the-dataset/
#has been modified to included QQ plots and SW tests
outlierKD <- function(dt, var, title, colVal) { 
     var_name <- eval(substitute(var),eval(dt))
     na1 <- sum(is.na(var_name))
     m1 <- mean(var_name, na.rm = T)
     
     par(mfrow=c(1, 3), oma=c(0,0,3,0))
     
     hist(var_name, main=paste("Histogram with outliers", title), 
          col= colVal, density = 10, xlab=title)
     boxplot(var_name, main=paste("Boxplot with outliers", title), 
             col = colVal, ylab = title)
     qqnorm(var_name, main=paste("Q-Q plot with outliers", title), col = colVal) 
     qqline(var_name, col = colVal)
     
     pval <- shapiro.test(var_name)[2]
     test <- pval > 0.05
     cat("p-value with outliers from Shapiro test is", toString(pval), "\n")
     cat("It is", test, "that the p-value > 0.05\n")
     cat("If above is TRUE, then data are normally distributed.\n")
     cat("If above is FALSE, then data are not normally distributed.")
     
     outlier <- boxplot.stats(var_name)$out
     mo <- mean(outlier)
     var_name <- ifelse(var_name %in% outlier, NA, var_name)
     
     hist(var_name, main=paste("Histogram without outliers", title), 
          col= colVal, density = 10, xlab=title)
     boxplot(var_name, main=paste("Boxplot without outliers", title), 
             col = colVal, ylab = title)
     qqnorm(var_name, main=paste("Q-Q plot without outliers", title), col = colVal) 
     qqline(var_name, col = colVal)
     
     dt[as.character(substitute(var))] <- invisible(var_name)
     assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
     
     pval <- shapiro.test(var_name)[2]
     test <- pval > 0.05
     cat("p-value without outliers from Shapiro test is", toString(pval), "\n")
     cat("It is", test, "that the p-value > 0.05\n")
     cat("If above is TRUE, then data are normally distributed.\n")
     cat("If above is FALSE, then data are not normally distributed.")
}
```


```{r load_data}
loadPkg(faraway)
ozdf = faraway::ozone
#colSums(!is.na(ozdf))
str(ozdf)
summary(ozdf)
```

```{r}
fit1 <- lm(vis ~ wind+humidity+ibt, data = ozdf)
fit2 <- lm(vis ~ wind+humidity+O3+vh+ibh, data = ozdf)
fit3 <- lm(vis ~ wind+humidity+O3+vh+ibh+temp+doy, data = ozdf)
anova_bic_cp <- anova(fit1,fit2)
anova_bic_r2 <- anova(fit1,fit3)
anova_cp_r2 <- anova(fit2,fit3)
anova_all3 <- anova(fit1,fit2,fit3)
```

## Ozone Dataset in LA (1976)  
This exercise uses the ozone dataset in the “[faraway](https://www.rdocumentation.org/packages/faraway/versions/1.0.7/topics/ozone)” package. 


### Question 1

**Quick check on the summary pdf for Pearson vs Spearman.**  

Done. Noted.


### Question 2 
**Determine if the `O3` (ozone concentration) and `temp` variables are normal.** 

The code from Klodian Dhana has been modified. I have included two more input arguments into the function: one var for the specific `title` and one var for the `color` of the plot. I have also included QQ plots and the Shapiro-Wilk test for the $p$-value in the function, so that we may compare the Q-Q plots with and without outliers to each other. Using a histogram, boxplot, QQ plot, and the SW test, we should be able to tell if the variables `O3` and `temp` are normal or not.  

```{r q2_O3}
outlierKD(ozdf, O3, "\nozone concentration", "pink")
```

For `O3` the data does not look normal, and the SW tests says that the data are not normal either (the null hypothesis is rejected because of the low `p`-value).

```{r q2_temp}
outlierKD(ozdf, temp, "\ntemp", "lightblue")
```

For `temp` the data looks more normal than the `O3` data, but the SW tests says that the data are not normal either (the null hypothesis is rejected because of the low `p`-value).


### Question 3  
**Apply Pearson and Spearman measure on the two variables `O3` and `temp`. Which one of these two is suitable for this scenario according to the summary pdf, and why?**

```{r lib_cor, include=F}
loadPkg(reshape2)
loadPkg(ggplot2)
loadPkg(gridExtra)
```

Before I do anything I can look at the scatterplot of `O3` and `temp` and visually inspect for any correlation that I can see by eye.

```{r find_max_min}
colMax <- function(data) sapply(data, max, na.rm = TRUE)
colMin <- function(data) sapply(data, min, na.rm = TRUE)
```


```{r scatterplot_O3_temp}
ydata <- ozdf$temp
xdata <- ozdf$O3
linearMod <- lm(ydata ~ xdata)
summary(linearMod)
# minVal <- colMax(ozdf)[[1]]
# maxVal <- colMin(ozdf)[[1]]
# counts <- nrow(ozdf)-1
# newx <- seq(minVal, maxVal, by = (maxVal-minVal)/counts)
# conf_interval <- predict(linearMod, newdata=data.frame(x=newx), interval="confidence",
#                          level = 0.68)
plot(xdata, ydata, main="Scatterplot and linear regression of \ntemperature vs ozone concentration", xlab="O3", ylab="temp [F]", pch=19)
abline(linearMod, col="red")
# lines(newx, conf_interval[,2], col="red", lty=2)
# lines(newx, conf_interval[,3], col="red", lty=2)
```

From a visual inspection of the above scatterplot I would expect that `O3` and `temp` should be fairly strongly correlated. I would be surprised if the tests do not calculate higher positive correlation values between these two variables. Since Pearson's correlation is a measure of the linear relationship between two continuous random variables I have used linear regression to find a linear model between these two variables and plotted that result on the scatterplot as well. 

I have created a function to plot a correlation heat map based on an inputed dataframe and the specified method.

```{r func_to_plot_corr}
corr_plot <- function(dataName, methodUse) {
  corr <- round(cor(dataName, method = methodUse, use = "complete.obs"), 3)
  melted_cormat <- melt(corr)
  
  ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(color = "white") + 
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, 
                       limit = c(-1,1), space = "Lab", name=methodUse) + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 1, size = 12, hjust = 1), 
        axis.text.y = element_text(vjust = 1, size = 12, hjust = 1), 
        axis.title.x = element_blank(), axis.title.y = element_blank()) + 
  coord_fixed() + 
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 2)
}
```

First I apply the Pearson measure on the data. I will print out a correlation matrix as well as the Pearson correlation value between O3 and temp.

```{r corr_p}
pearson_plot <- corr_plot(ozdf, "pearson")
pearson_plot
res_p <- cor.test(ozdf$O3, ozdf$temp, method = "pearson")
res_p
```

Then I apply the Spearman measure on the data and I will print out a correlation matrix as well as the Spearman correlation value between O3 and temp.  

```{r corr_s}
spearman_plot <- corr_plot(ozdf, "spearman")
spearman_plot
res_s <- cor.test(ozdf$O3, ozdf$temp, method = "spearman")
res_s
```

Both of these tests have given me fairly strong positive correlation values. The Pearson method gives me that cor = `r res_p$estimate` whereas the Spearman method gives me that $\rho$ = `r res_s$estimate`. 


From the summary pdf we have:

Category | Pearson | Spearman |
---------|---------|----------|
Variable Type | Quantitative | Ranks  
Variable level | Interval/Ratio | Ordinal 
Type | Linear | Monotonic
Distribution | Normally distributed | Distribution free

In the  summary we are also given the following link for information: This exercise uses “[https://stats.stackexchange.com/questions/8071/how-to-choose-between-pearson-and-spearman-correlation](https://stats.stackexchange.com/questions/8071/how-to-choose-between-pearson-and-spearman-correlation).

The Pearson correlation is most appropriate for measurements taken from an interval scale, e.g. "temperature in Farenheit" and "length in inches", where the individual units (1 deg F, 1 in) are meaningful. The Spearman correlation is most appropriate for things like "satisfaction scores", or ordinal type variables, where it is clear that "5 happiness" is happier than "3 happiness" but there is not a quantitative value attached to "happiness". 

Because of the variable type I might have been inclined to use the Pearson test, since `O3` is a variable of type `r typeof(ozdf$O3)` and `temp` is a variable of type `r typeof(ozdf$temp)`. However, a concern of ours might be that our data are not normally distributed. This is when we consider that the Pearson's correlation is a measure of the linear relationship between two continuous random variables, and does not assume normality although it does assume finite variances and finite covariance. While Pearson's correlation does not assume normality, it is, however, only an exhaustive measure of association if the joint distribution is multivariate normal. 

I have already used linear regression to find a linear relationship between `O3` and `temp`. I believe that because it seems like these two variables seem to be strongly positively correlated, and do seem to have a linear relationship, that the Pearson's measure is suitable.


### Question 4  
**Make a model for visibility (`vis`) with other variables as predictors in the dataset.**  
*Since we do not have a lot of variables, we can use the exhaustive method in regsubsets to identify what factors are best used to predict visibility. Also select `nbest = 2`. According to adjusted R2, what is the best model? What are the features to use?  Build out that model and find the adjusted R2 value as well as the VIF. Are you pleased with this model?*

From the class lectures we were told about `leaps::regsubsets()` and `subsets()`. I will use them here to make a model for visibility (`vis`). We used `nvmax=10` and `nbest=2` as options here. As a result, you will find two 10-variable models, two 9-variable models, two 8-variable models, etc. 

```{r leaps_regsubsets}
loadPkg(leaps)
#This is essentially best fit 
reg.best10 <- regsubsets(vis~. , data = ozdf, nvmax = ncol(ozdf), nbest = 2, method = "exhaustive")  # leaps::regsubsets() - Model selection by exhaustive (default) search, forward or backward stepwise, or sequential replacement
#The plot will show the Adjust R^2 when using the variables across the bottom
plot(reg.best10, scale = "adjr2", main = "Adjusted R^2")
#plot(reg.best10, scale = "r2", main = "R^2")
```

We can also use the function `subsets()` to plot. 

```{r car_subsets}
loadPkg(car)

summaryRegForward = summary(reg.best10)
# Adjusted R2
subsets(reg.best10, statistic="adjr2", legend = FALSE, min.size = 2, main = "Adjusted R^2")
```

For `vis` I have looked at models that include all the variables in the dataset down to only 2 variables. For the adjusted R^2 value I want the highest value for the model. It seems that we have several models with many variables that all have around the same adjusted R^2 value. I would like to maximize my R^2 value and minimze my number of variables. I will use the top-most model in the above plots to build my model. This model includes `O3`, `vh`, `wind`, `humidity`, `temp`, `ibh`, and `doy` with an adjusted R^2 value of 0.32.

```{r build_model_r2}
#model1 <- lm(vis ~., data = ozdf)
model_r2 <- lm(vis ~ wind + humidity + O3 + vh + ibh + temp + doy, data = ozdf)
summary(model_r2)
```

I have built my model using the above specified variables. The adjusted R^2 value is `r summary(model_r2)$adj.r.squared`. I can also find the VIF.  

```{r vif_model_r2}
vif_model_r2 <- vif(model_r2)
vif_model_r2
```

To use the VIF we have the following rules of thumb

VIF | meaning |
----|---------|
1 | not correlated |
between 1 and 5 | moderately correlated |
greater than 5 | highly correlated |

I can go through all the values and determine whether the variables are correlated or not to `vis`.

```{r determine_corr_model_r2}
vif_vals_m1 <- list()
corr_cond_m1 <- list()
for(i in 1:length(vif_model_r2)) {
  vif_vals_m1[i] <- vif_model_r2[[i]]
  
  if(vif_model_r2[[i]] < 1) {
    corr_cond_m1[i] <- "not correlated"
  }
  
  if(vif_model_r2[[i]] > 1 & vif_model_r2[[i]] < 5) {
    corr_cond_m1[i] <- "moderately correlated"
  }
  
  if(vif_model_r2[[i]] > 5) {
    corr_cond_m1[i] <- "highly correlated"
  }
}
vif_vals_m1 <- unlist(vif_vals_m1)
corr_cond_m1 <- unlist(corr_cond_m1)
vif_m1_df <- do.call(rbind, Map(data.frame, "variable"=names(vif_model_r2), 
                                "vif.value"=vif_vals_m1, "condition"=corr_cond_m1))

loadPkg(kableExtra)
vif_m1_df %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

I am not very happy with this model because the adjusted R^2 value is only `r summary(model_r2)$adj.r.squared` and most of the variables are only moderately correlated with `vis`.  

### Question 5  
**From the same result in the previous question, but use BIC instead.**  
*Build the best model with this criterion and find the adjusted R2 as well as VIF. Are you pleased with this model?*

I can make the same plots as before, but this time use BIC instead of the adjusted R^2 to find the best model. 

```{r bic_plots}
plot(reg.best10, scale = "bic", main = "BIC")
subsets(reg.best10, statistic="bic", legend = FALSE, min.size = 2, main = "BIC")
```

Wow, these models are much different than the ones suggested by the adjusted R^2. In general, BIC criteria tends to favor more predictive model, with fewer regressors. For BIC we are looking for the smallest value, rather than the largest, like we did for the adjusted R^2. According the BIC the best model with BIC = -96 includes the `wind`, `humidity`, and `ibt`. We can build this best model and find the adjusted R^2 and VIF from this model.

```{r bic_model}
model_bic <- lm(vis ~ wind + humidity + ibt, data = ozdf)
summary(model_bic)
vif_model_bic <- vif(model_bic)
vif_model_bic
```

From the model made from the best BIC value we see that the Adjusted R^2 value is `r summary(model_bic)$adj.r.squared`. I am going to check the VIF values like I did in the previous section.

```{r vif_bic}
vif_vals_bic <- list()
corr_cond_bic <- list()
for(i in 1:length(vif_model_bic)) {
  vif_vals_bic[i] <- vif_model_bic[[i]]
  
  if(vif_model_bic[[i]] < 1) {
    corr_cond_bic[i] <- "not correlated"
  }
  
  if(vif_model_bic[[i]] > 1 & vif_model_bic[[i]] < 5) {
    corr_cond_bic[i] <- "moderately correlated"
  }
  
  if(vif_model_bic[[i]] > 5) {
    corr_cond_bic[i] <- "highly correlated"
  }
}
vif_vals_bic <- unlist(vif_vals_bic)
corr_cond_bic <- unlist(corr_cond_bic)
vif_df_bic <- do.call(rbind, Map(data.frame, "variable"=names(vif_model_bic), 
                                "vif.value"=vif_vals_bic, "condition"=corr_cond_bic))

#loadPkg(kableExtra)
vif_df_bic %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

I am also not satisfied with this model. While the variables are more significant to the model (by looking at the p-values), the adjusted R^2 value is less than in the previous section, and also all the variables are only moderately correlated to `vis`.


### Question 6   
**To use $C_p$, we should use the stopping rule of $C_p$ ≈ (# regressors + 1).**  
*Follow the example in class (or [this example](https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html)) to produce a visual graph for the task. Build out the best model again and find the adjusted R2 value and VIF.* 

I can, once again, make plots in the similar way as in the previous questions, and this method is based on the one shown in class.

```{r cp_plots}
plot(reg.best10, scale = "Cp", main = "Mallow Cp")
subsets(reg.best10, statistic="cp", legend = FALSE, min.size = 3, main = "Mallow Cp")
abline(a = 1, b = 1, lty = 2)
```

The Cp value is similar to the BIC in that you want the smallest value. According the the Cp value (which is 6.1) the best model is `O3`, `vh`, `wind`, `humidity`, `ibh`, and `doy`. This model is incredibly similar to the best model suggested by the adjusted R^2.

```{r cp_model}
model_cp <- lm(vis ~ wind + humidity + O3 + vh + ibh, data = ozdf)
summary(model_cp)
vif_model_cp <- vif(model_cp)
vif_model_cp
```

From the model made from the best Cp value we see that the Adjusted R^2 value is `r summary(model_cp)$adj.r.squared`. I am going to check the VIF values like I did in the previous section.

```{r vif_cp}
vif_vals_cp <- list()
corr_cond_cp <- list()
for(i in 1:length(vif_model_cp)) {
  vif_vals_cp[i] <- vif_model_cp[[i]]
  
  if(vif_model_cp[[i]] < 1) {
    corr_cond_cp[i] <- "not correlated"
  }
  
  if(vif_model_cp[[i]] > 1 & vif_model_cp[[i]] < 5) {
    corr_cond_cp[i] <- "moderately correlated"
  }
  
  if(vif_model_cp[[i]] > 5) {
    corr_cond_cp[i] <- "highly correlated"
  }
}
vif_vals_cp <- unlist(vif_vals_cp)
corr_cond_cp <- unlist(corr_cond_cp)
vif_df_cp <- do.call(rbind, Map(data.frame, "variable"=names(vif_model_cp), 
                                "vif.value"=vif_vals_cp, "condition"=corr_cond_cp))

#loadPkg(kableExtra)
vif_df_cp %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

The Adjusted R^2 value is `r summary(model_cp)$adj.r.squared`, which is still not very high, and the parameters are only moderately correlated with `vis`. I am still not very happy with the fits here.


### Question 7   
**While you are at Question 6, also produce the graph for using adjusted R2 as criterion.**  
*This won’t change the result in Question 4. This is just an alternative visualization for the adjusted R2 case. We can see better how different are the nearby models.*

Here is the graph using the adjusted R^2 as the criterion. 

```{r r2_plot}
subsets(reg.best10, statistic="adjr2", legend = FALSE, min.size = 3, main = "Adjusted R2")
```

### Question 8  
**Using ANOVA, compare the models you found in questions 4, 5, and 6.**  
*Comment on the result.*

I can use ANOVA to compare nested models and it will tell me if the added complexity makes the model better than the simpler model or not. The model made by BIC is the simplest, and then I will use the Cp model and then finally the adjusted R^2 model. 

First I can compare the model made from the best BIC value to the model made from the best Cp value.

```{r anova_bic_cp_test}
anova_bic_cp 
pvalue_bic_cp <- anova_bic_cp$"Pr(>F)"
```

The $p$-value is `r pvalue_bic_cp[2]`. The added complexity of the model made from the best Cp value does not make a better model than the less complex model made from the best BIC model, according to this ANOVA test and the $p$-value.

Then I can compare the model made from the best BIC value to the model made from the best adjusted R2 value.

```{r anova_bic_r2_test}
anova_bic_r2
pvalue_bic_r2 <- anova_bic_r2$"Pr(>F)"
```

The $p$-value is `r pvalue_bic_r2[2]`. Due to this $p$-value we see that the added complexity of the model made from the best adjusted R2 value is actually better than the model made from the best BIC value. 

Then I can compare the model made from the best Cp value to the model made from the best adjusted R2 value.

```{r anova_cp_r2_test}
anova_cp_r2
pvalue_cp_r2 <- anova_cp_r2$"Pr(>F)"
```

The $p$-value is `r pvalue_cp_r2[2]`. Like when comparing the BIC model to the adjusted R@ model, we see that the added complexity of the model made from the best adjusted R2 value is actually better than the model made from the best Cp value.

Finally I can compare all 3 models at once: the BIC model (least complex) to the Cp model to the adjusted R2 model (most complex). 

```{r anova_all3_test}
anova_all3
pvalue_all3 <- anova_all3$"Pr(>F)"
```

We see that the model made from the best Cp value is not favored by the ANOVA test ($p$-value when comparing BIC model to Cp model is `r pvalue_all3[2]`), but the model made from the best adjusted R2 value is preferred to the model made from the best BIC value ($p$-value when comparing Cp model to adjusted R2 model is `r pvalue_all3[3]`). However, a caution. This $p$-value is not incredibly significant. This suggests that the model made from the best adjusted R2 is only slightly better than the less complex model made from the best BIC method.  


```{r, include=FALSE}
unloadPkg(faraway)
unloadPkg(leaps)
unloadPkg(reshape2)
unloadPkg(ggplot2)
unloadPkg(gridExtra)
unloadPkg(car)
unloadPkg(kableExtra)
```



